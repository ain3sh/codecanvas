\begin{abstract}
Coding agents break what they can't see. LLM-based code editors often introduce regressions by editing without inspecting the dependency surface: callers, tests, and downstream consumers that must stay consistent. We call this failure mode \emph{side-effect blindness}. The problem worsens when action history falls out of context, so agents forget what they checked or decided and repeat exploration.

We present \textbf{CodeCanvas}, an MCP tool that gives \emph{impact visibility} and preserves reasoning across context windows. CodeCanvas renders a visual codemap of blast radius around the current file or symbol and maintains an Evidence Board that records claims, evidence, and decisions as an action history that survives context compaction. Both artifacts are injected automatically through deterministic hooks, so agents receive impact cues at the moment they choose an edit.

On seven Terminal-Bench 2.0 tasks under a fixed Harbor + Claude Code harness, CodeCanvas solves 4/7 tasks vs 3/7 for both a text-only baseline and a graph-based baseline (LocAgent), with less backtracking (2.14 vs 4.57 average) and lower cost per success (4.56M vs 7.80M tokens). We also propose the \emph{Informed Editing Score} as a process metric for impact-aware editing. Results are descriptive, given single trials per condition due to budget limitations.
\end{abstract}

\vfill\eject
